# app/services/chat_service.py
"""
Chat GPT para SurveySaaS  â€“  OpenAI v1  (sin embeddings)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Conversa normalmente y sÃ³lo pregunta la secciÃ³n si de verdad falta.
â€¢ Si el usuario responde â€œplantillasâ€, â€œcampaÃ±asâ€, etc., lo tomamos como secciÃ³n.
â€¢ Function-calling: create_template  â†’  inserta plantilla + preguntas/opciones.
"""

from __future__ import annotations
import os, json
from uuid import UUID
from typing import Any, Dict, List, Optional

from openai import OpenAI
from sqlalchemy.orm import Session

from app.schemas.plantillas_schema import PlantillaCreate
from app.schemas.preguntas_schema import PreguntaCreate, OpcionCreate
from app.services.plantillas_service import create_plantilla
from app.services.preguntas_service import create_pregunta
from app.services.opciones_service import create_opcion
from app.models.cuenta_usuario import CuentaUsuario

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
OPENAI_MODEL   = os.getenv("OPENAI_MODEL", "gpt-4o")  
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise RuntimeError("Debes definir OPENAI_API_KEY en .env")

client = OpenAI(api_key=OPENAI_API_KEY)

GLOBAL_CONTEXT = """
Eres el asistente virtual de SurveySaaS.
Secciones principales: Plantillas, CampaÃ±as, Destinatarios, Entregas, Respuestas.
Responde siempre en espaÃ±ol. Si no recibes â€˜route/sectionâ€™ y lo necesitas,
pregunta UNA sola vez: Â«Â¿En quÃ© parte de la aplicaciÃ³n estÃ¡s?Â».
Si recibes el bloque â€œðŸ§­ Contexto de pantallaâ€ NO vuelvas a preguntar.
Cuando ejecutes una funciÃ³n, explica primero lo que harÃ¡s y luego confirma.
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Tools (function-calling) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "create_template",
            "description": "Crea una plantilla con preguntas y opciones",
            "parameters": {
                "type": "object",
                "properties": {
                    "nombre":      {"type": "string"},
                    "descripcion": {"type": "string"},
                    "preguntas": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "orden":            {"type": "integer"},
                                "texto":            {"type": "string"},
                                "tipo_pregunta_id": {"type": "integer"},
                                "obligatorio":      {"type": "boolean"},
                                "opciones": {
                                    "type": "array",
                                    "items": {"type": "string"},
                                    "nullable": True,
                                },
                            },
                            "required": ["texto", "tipo_pregunta_id", "obligatorio"],
                        },
                    },
                },
                "required": ["nombre", "preguntas"],
            },
        },
    }
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
_SECCIONES = {"plantillas", "campaÃ±as", "destinatarios", "entregas", "respuestas", "dashboard"}

def _suscriptor_id(token_data, db: Session) -> UUID:
    """Devuelve el suscriptor_id segÃºn el rol del token."""
    if token_data.role == "empresa":
        return UUID(token_data.sub)
    user = db.query(CuentaUsuario).get(UUID(token_data.sub))
    if not user:
        raise RuntimeError("Operador no encontrado")
    return user.suscriptor_id

def _build_msgs(user_msg: str, ctx: Optional[dict]) -> List[dict]:
    """
    Crea la lista de mensajes para OpenAI:
    â€¢ GLOBAL_CONTEXT
    â€¢ ðŸ§­ Contexto de pantalla   (si llega o si deducimos la secciÃ³n)
    â€¢ Mensaje del usuario
    """
    if not ctx:
        maybe = user_msg.strip().lower()
        if maybe in _SECCIONES:
            ctx = {"route": "N/A", "section": maybe}

    msgs = [{"role": "system", "content": GLOBAL_CONTEXT}]
    if ctx:
        pantalla = f"{ctx.get('section')} ({ctx.get('route')})"
        msgs.append({"role": "system", "content": f"ðŸ§­ Contexto de pantalla: {pantalla}"})
    msgs.append({"role": "user", "content": user_msg})
    return msgs

def _crear_plantilla(db: Session, suscriptor_id: UUID, args: Dict[str, Any]) -> Dict[str, Any]:
    """Inserta plantilla + preguntas/opciones. Devuelve objeto y log."""
    plantilla = create_plantilla(
        db,
        PlantillaCreate(
            nombre=args["nombre"],
            descripcion=args.get("descripcion"),
        ),
        suscriptor_id,
    )

    log = [f"Plantilla creada (id={plantilla.id})"]

    for idx, p in enumerate(args["preguntas"], 1):
        pregunta = create_pregunta(
            db,
            plantilla.id,
            PreguntaCreate(
                orden=p.get("orden"),
                texto=p["texto"],
                tipo_pregunta_id=p["tipo_pregunta_id"],
                obligatorio=p["obligatorio"],
            ),
        )
        log.append(f" â€“ Pregunta {idx}: id={pregunta.id}")

        for j, texto in enumerate(p.get("opciones") or [], 1):
            opcion = create_opcion(db, pregunta.id, OpcionCreate(texto=texto))
            log.append(f"   â€¢ OpciÃ³n {j}: id={opcion.id}")

    return {"plantilla": plantilla, "action_log": log}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Entrada principal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
async def chat_completion(
    db: Session,
    token_data,
    message: str,
    context: Optional[dict] = None,
    history: Optional[List[dict]] = None,   # â† si quieres pasar historial
) -> Dict[str, Any]:
    """
    Devuelve:
        answer      -> texto al usuario
        action_log  -> acciones ejecutadas para transparencia
    """
    base_msgs = _build_msgs(message, context)
    msgs = (history or [])[-6:] + base_msgs  

    resp = client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=msgs,
        tools=TOOLS,
        tool_choice="auto",
        temperature=0.3,
    ).choices[0]

    # â€”â€”â€” Function-call â€”â€”â€”
    if resp.finish_reason == "tool_calls":
        call = resp.message.tool_calls[0]
        if call.function.name == "create_template":
            args = json.loads(call.function.arguments)  # arguments llega como string
            r = _crear_plantilla(db, _suscriptor_id(token_data, db), args)
            return {
                "answer": (
                    f"Voy a crear la plantilla Â«{args['nombre']}Â»â€¦\n"
                    f"Â¡Listo! Plantilla Â«{r['plantilla'].nombre}Â» creada con Ã©xito."
                ),
                "action_log": r["action_log"],
            }

    # â€”â€”â€” Respuesta normal â€”â€”â€”
    return {"answer": resp.message.content.strip(), "action_log": []}
